{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on March 23 (with a 2-hour grace period)  \n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with a well-known Kaggle dataset—the Pima Indians Diabetes dataset—to determine whether an individual has diabetes (1) or not (0). This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- Instead of `RepeatedKFold` we use `RepeatedStratifiedKFold` (read the docs to understand the difference)\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score) instead of regression metrics--for simplicity we'll just use accuracy in this homework. \n",
    "\n",
    "For this assignment, you’ll build two models and measure their performance using the accuracy metric. \n",
    "1. A **logistic regression** classifier as a baseline.\n",
    "2. One of the **ensemble** classifiers of your choice.\n",
    "\n",
    "Because we’ve already covered much of the workflow in our regression assignments, this homework is intentionally concise and less prescriptive.\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 5 graded problems, each worth 5 points, for a total of 25 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold,GridSearchCV\n",
    "from sklearn.ensemble        import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from tqdm                    import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# globals\n",
    "\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem One:  Load, Explore, and Preprocess the Kaggle Pima Indians Diabetes Dataset \n",
    "\n",
    "In the follow cell(s), \n",
    "- Download the dataset from Kaggle\n",
    "- Perform some simple EDA using `.head()`, `.info()` and `.hist()`\n",
    "    - When using a classification dataset, **always** look to see whether the target is balanced (approximately equal numbers of classes) or not. \n",
    "- Create the feature set `X` and the target set `y` (using `Outcome` as the target)\n",
    "- Scale `X` using `StandardScalar` (since the classification models often prefer this)\n",
    "- Split the dataset into 80% training and 20% testing sets\n",
    "- Verify that the graded answer is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/uciml/pima-indians-diabetes-database/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/pima-indians-diabetes-database\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "filename = 'diabetes.csv'\n",
    "\n",
    "csv_path = os.path.join(path,filename)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(12,12),layout = (-1,3),bins = 50, edgecolor = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = ((614, 8), (154, 8))\n"
     ]
    }
   ],
   "source": [
    "# Nothing to do, but you might want to check and make sure this is correct\n",
    "\n",
    "a1 = (X_train.shape,X_test.shape)                          \n",
    "\n",
    "print(f'a1 = {a1}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: Wrapper Functions for Running Classification Models\n",
    "\n",
    "The following cells are adapted from the Week 7 homework in order to use accuracy as the error metric. You can easily modify these\n",
    "if you wish to consider other metrics.  \n",
    "\n",
    "\n",
    "**Note:** `sweep_parameter` sets `X_train` etc. to default values using the global values for `X_train` etc. you created in problem 1.  Should work fine as is, but you can always just ignore the defaults and assign the parameters explicitly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, **model_params):\n",
    "\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    \n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_preds     = model.predict(X_test)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    return mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sweep_parameter(model,\n",
    "                    Parameters,\n",
    "                    param,\n",
    "                    parameter_list,\n",
    "                    X_train          = X_train,                 # The defaults use global parameters, you can override this by simply giving the arguments explicitly\n",
    "                    y_train          = y_train,\n",
    "                    X_test           = X_test,\n",
    "                    y_test           = y_test,\n",
    "                    verbose          = True,\n",
    "                    n_iter_no_change = None,\n",
    "                    delta            = 0.001,\n",
    "                    n_jobs           = -1,\n",
    "                    n_repeats        = 10\n",
    "                   ):\n",
    "\n",
    "    start = time.time()\n",
    "    Parameters = Parameters.copy()  # Avoid modifying the original dictionary\n",
    "    \n",
    "    cv_accuracies, std_cvs, train_accuracies, test_accuracies = [], [], [], []\n",
    "    no_improve_count = 0\n",
    "    best_accuracy = -np.inf  # since higher accuracy is better\n",
    "    \n",
    "    # Run over each value in parameter_list\n",
    "    for p in tqdm(parameter_list, desc=f\"Sweeping {param}\"):\n",
    "        Parameters[param] = p\n",
    "        P_temp = Parameters.copy()\n",
    "        # Remove accuracy_found if present, just in case\n",
    "        P_temp.pop('accuracy_found', None)\n",
    "        \n",
    "        # run_model should return: mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy\n",
    "        mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy = run_model(\n",
    "            model=model,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=n_jobs,\n",
    "            **P_temp\n",
    "        )\n",
    "        cv_accuracies.append(mean_cv_accuracy)\n",
    "        std_cvs.append(std_cv_accuracy)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # Early-stopping logic: maximize accuracy\n",
    "        if mean_cv_accuracy > best_accuracy + delta:\n",
    "            best_accuracy = mean_cv_accuracy\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "        \n",
    "        if n_iter_no_change is not None and no_improve_count >= n_iter_no_change:\n",
    "            print(f\"Early stopping: No improvement after {n_iter_no_change} iterations.\")\n",
    "            break\n",
    "    \n",
    "    # Identify best parameter\n",
    "    max_cv_accuracy = max(cv_accuracies)\n",
    "    max_index = cv_accuracies.index(max_cv_accuracy)\n",
    "    best_param = parameter_list[max_index]\n",
    "    Parameters[param] = best_param\n",
    "    Parameters['accuracy_found'] = max_cv_accuracy\n",
    "    \n",
    "    if verbose:\n",
    "        # Prepare for plotting\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "        \n",
    "        # Use only as many parameter values as computed\n",
    "        partial_param_list = parameter_list[:len(cv_accuracies)]\n",
    "        \n",
    "        # Check if our parameter list is Boolean for proper labeling\n",
    "        is_boolean = all(isinstance(val, bool) for val in partial_param_list)\n",
    "        if is_boolean:\n",
    "            # Convert booleans to integer indices for plotting\n",
    "            x_vals = list(range(len(partial_param_list)))\n",
    "            x_labels = [str(val) for val in partial_param_list]\n",
    "        else:\n",
    "            x_vals = partial_param_list\n",
    "            x_labels = partial_param_list\n",
    "        \n",
    "        # ----- First plot: Accuracy -----\n",
    "        ax1.set_title(f\"Accuracy vs {param}\")\n",
    "        \n",
    "        ax1.plot(x_vals,\n",
    "                 cv_accuracies,\n",
    "                 marker='.', label=\"CV Accuracy\", color='blue')\n",
    "        ax1.plot(x_vals,\n",
    "                 train_accuracies,\n",
    "                 marker='.', label=\"Train Accuracy\", color='green')\n",
    "        ax1.plot(x_vals,\n",
    "                 test_accuracies,\n",
    "                 linestyle='--', label=\"Test Accuracy\", color='orange')\n",
    "        ax1.scatter([x_vals[max_index]],\n",
    "                    [max_cv_accuracy],\n",
    "                    marker='x', label=\"Best CV Accuracy\", color='red')\n",
    "        \n",
    "        ax1.set_ylabel(\"Accuracy\")\n",
    "        ax1.legend()\n",
    "        ax1.grid()\n",
    "        \n",
    "        # ----- Second plot: CV Standard Deviation -----\n",
    "        ax2.set_title(f\"CV Standard Deviation vs {param}\")\n",
    "        ax2.plot(x_vals, std_cvs, marker='.', label=\"CV Accuracy Std\", color='blue')\n",
    "        ax2.set_xlabel(param)\n",
    "        ax2.set_ylabel(\"Standard Deviation\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(alpha=0.5)\n",
    "        \n",
    "        # If using boolean x-values, set custom ticks\n",
    "        if is_boolean:\n",
    "            ax2.set_xticks(x_vals)\n",
    "            ax2.set_xticklabels(x_labels)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)))\n",
    "    \n",
    "    return Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two: Classification using Logistic Regression (Baseline)  \n",
    "\n",
    "For this problem,\n",
    "- Read the docs for `LogisticRegression`\n",
    "- Run the model with `class_weight = 'balanced'` and `max_iter=1000` using `run_model` or just your own code. \n",
    "- Answer the graded questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV Acc: 75.26%\n",
      "Std CV Acc: 0.0291\n",
      "Train Acc: 76.06%\n",
      "Test Acc: 69.48%\n"
     ]
    }
   ],
   "source": [
    "# Your code; add as many cells as you need\n",
    "\n",
    "Params_LR = { \n",
    "        'class_weight': 'balanced',\n",
    "        'max_iter': 1000,\n",
    "        'random_state': 42\n",
    "}\n",
    "\n",
    "mean_cv_accuracy,std_cv_accuracy,train_accuracy,test_accuracy = \\\n",
    "        run_model(LogisticRegression,X_train,y_train,X_test,y_test,n_repeats = 10,n_jobs = -1, **Params_LR)\n",
    "\n",
    "\n",
    "print(f'Mean CV Acc: {mean_cv_accuracy *100:.2f}%')\n",
    "print(f'Std CV Acc: {std_cv_accuracy:.4f}')\n",
    "print(f'Train Acc: {train_accuracy *100:.2f}%')\n",
    "print(f'Test Acc: {test_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.A Graded Answer\n",
    "\n",
    "Provide the mean CV accuracy score of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = 0.7526\n"
     ]
    }
   ],
   "source": [
    "# Insert the mean CV accuracy\n",
    "\n",
    "a2a = mean_cv_accuracy                              # Just to get it to run without errors, put your answer here                       \n",
    "\n",
    "print(f'a2a = {a2a:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.B Graded Answer\n",
    "\n",
    "Provide the test accuracy of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b = 0.6948\n"
     ]
    }
   ],
   "source": [
    "# Insert the test accuracy\n",
    "\n",
    "a2b = test_accuracy                               # Just to get it to run without errors, put your answer here                          \n",
    "\n",
    "print(f'a2b = {a2b:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three: Classification using Ensemble Methods  \n",
    "\n",
    "For this problem,\n",
    "- Choose one of the ensemble methods for classification (see the first code cell above)\n",
    "- Read about the hyperparameters for the model in the `sklearn` docs\n",
    "- Tune the model for best performance using the wrapper functions and/or grid search as needed\n",
    "- Answer the graded questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sweeping n_estimators:   0%|          | 0/5 [00:00<?, ?it/s]/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 107, in _check_targets\n",
      "    raise ValueError(\n",
      "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
      "\n",
      "  warnings.warn(\n",
      "Sweeping n_estimators:   0%|          | 0/5 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m parameters_and_reanges \u001b[38;5;241m=\u001b[39m[ (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m81\u001b[39m, \u001b[38;5;241m10\u001b[39m)),\n\u001b[1;32m     16\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m]),\n\u001b[1;32m     17\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m1\u001b[39m) ),\n\u001b[1;32m     18\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m,[\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[1;32m     19\u001b[0m                            ]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (param,parameter_list) \u001b[38;5;129;01min\u001b[39;00m parameters_and_reanges:\n\u001b[0;32m---> 22\u001b[0m         Parameters_RF \u001b[38;5;241m=\u001b[39m \u001b[43msweep_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mParameters_RF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mparameter_list\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m#print (f\"Parameter {param} = {Parameters_RF[param]} ,RMSE = ${Parameters_RF['MSE_found'] ** 0.5:0.2f} \")\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(Parameters_RF)\n",
      "Cell \u001b[0;32mIn[34], line 31\u001b[0m, in \u001b[0;36msweep_parameter\u001b[0;34m(model, Parameters, param, parameter_list, X_train, y_train, X_test, y_test, verbose, n_iter_no_change, delta, n_jobs, n_repeats)\u001b[0m\n\u001b[1;32m     28\u001b[0m P_temp\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy_found\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# run_model should return: mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m mean_cv_accuracy, std_cv_accuracy, train_accuracy, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mP_temp\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m cv_accuracies\u001b[38;5;241m.\u001b[39mappend(mean_cv_accuracy)\n\u001b[1;32m     40\u001b[0m std_cvs\u001b[38;5;241m.\u001b[39mappend(std_cv_accuracy)\n",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(model, X_train, y_train, X_test, y_test, n_repeats, n_jobs, **model_params)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Compute training and testing accuracy\u001b[39;00m\n\u001b[1;32m     28\u001b[0m train_preds    \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m---> 29\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m test_preds     \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     31\u001b[0m test_accuracy  \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, test_preds)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    109\u001b[0m             type_true, type_pred\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "# Your code here\n",
    "Default_Parameters_Random_Forests = {\n",
    "        'n_estimators': 100,         # Number of base estimators in the ensemble\n",
    "        'max_features': None,        # Number of features to consider when looking for the best split \n",
    "       'max_depth'   : None,        # Limits the depth of each tree\n",
    "        'bootstrap'   : True,        # Use bootstrap samples when building estimators\n",
    "        'random_state': 42,          # Ensures reproducibility\n",
    "    }\n",
    "  \n",
    "\n",
    "\n",
    "Parameters_RF = Default_Parameters_Random_Forests.copy()\n",
    "Parameters_RF_list = []\n",
    "parameters_and_reanges =[ ('n_estimators', range(40, 81, 10)),\n",
    "                           ('max_depth', [None, 10, 20, 30]),\n",
    "                           ('max_features', range(8, 15, 1) ),\n",
    "                           ('bootstrap',[True,False])\n",
    "                           ]\n",
    "\n",
    "for (param,parameter_list) in parameters_and_reanges:\n",
    "        Parameters_RF = sweep_parameter(RandomForestRegressor,\n",
    "                                    Parameters_RF,\n",
    "                                    param,\n",
    "                                    parameter_list\n",
    "    \n",
    "                                    )\n",
    "        #print (f\"Parameter {param} = {Parameters_RF[param]} ,RMSE = ${Parameters_RF['MSE_found'] ** 0.5:0.2f} \")\n",
    "        print(Parameters_RF)\n",
    "        print()\n",
    "Parameters_RF_list.append(Parameters_RF)\n",
    "    \n",
    "pd.DataFrame(Parameters_RF_list)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.0s\n",
      "\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Best hyperparameters and the corresponding accuracy\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1023\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1018\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1023\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1570\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1570\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:969\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    965\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    966\u001b[0m         )\n\u001b[1;32m    967\u001b[0m     )\n\u001b[0;32m--> 969\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and the corresponding accuracy\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.A Graded Answer\n",
    "\n",
    "Provide the mean CV accuracy score of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the mean CV accuracy\n",
    "\n",
    "a3a = 0.0                              # Just to get this cell to run without errors, put your answer here                 \n",
    "\n",
    "print(f'a3a = {a3a:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.B Graded Answer\n",
    "\n",
    "Provide the test accuracy of your best model in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the test accuracy\n",
    "\n",
    "a3b = 0.0                              # Just to get this cell to run without errors, put your answer here \n",
    "\n",
    "print(f'a3b = {a3b:.4f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
